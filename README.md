# ModelInferBench
For testing model inference speed

python test_python.py

## Windows

13900
32G DDR4 3000
1070ti

efficientnet_b4  1, 3, 224, 224

batch_size 1
cpu 171.536 ms
gpu 10.715 ms
onnx cpu 39.876 ms
onnx gpu 23.337 ms

batch_size 4
cpu 513.850 ms
gpu 25.534 ms
onnx cpu 46.736 ms
onnx gpu 18.768 ms